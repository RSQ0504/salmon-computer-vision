@inproceedings{10.1145/2764873.2764875,
author = {Wang, Nancy Xin Ru and Cullis-Suzuki, Sarika and Branzan Albu, Alexandra},
title = {Automated Analysis of Wild Fish Behavior in a Natural Habitat},
year = {2015},
isbn = {9781450335584},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.sfu.ca/10.1145/2764873.2764875},
doi = {10.1145/2764873.2764875},
abstract = {This paper proposes a novel approach for the analysis of movement and behavior of the Plainfin midshipman (Porichthys notatus) in the wild. It is based on underwater video recordings of the fish in their natural habitat taken inside their nests during reproductive months. During this time, alpha male Plainfin midshipmen rarely leave their nests as they are guarding their eggs, so the proposed approach addresses the issue of detecting subtle motion and nesting behavior as the fish remains relatively sedentary. To the best of our knowledge, this is the first paper to propose an automated method to analyze subtle movements of a highly territorial animal in its natural habitat.Motion detection uses the displacement of SURF (Interest point algorithm) key-point movements from frame to frame to analyze the amount of movement by the fish. K-means clustering and other outlier removal techniques are then used to differentiate fish motion from small moving objects in the background and foreground. The analysis of fish behavior uses similarity-based periodicity detection combined with the K-neighbors classifier. Experimental validation with respect to expert-annotated ground truth shows excellent performance for both motion and behavior detection approaches.},
booktitle = {Proceedings of the 2nd International Workshop on Environmental Multimedia Retrieval},
pages = {21–26},
numpages = {6},
location = {Shanghai, China},
series = {EMR '15}
}

@inproceedings{10.1145/3325917.3325934,
author = {Manandhar, Nibha and Burris, John W.},
title = {An Application of Image Classification to Saltwater Fish Identification in Louisiana Fisheries},
year = {2019},
isbn = {9781450366359},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.sfu.ca/10.1145/3325917.3325934},
doi = {10.1145/3325917.3325934},
abstract = {Fish identification is a challenge to recreational anglers, but critically important to the management of fisheries. The state of Louisiana currently provides printed illustrations of species as the sole aid to anglers for the process of fish identification. This work describes the application of Google's TensorFlow machine learning library to the task of fish identification as a case study on the application of the image classification capabilities. We describe the implementation and results of the project.},
booktitle = {Proceedings of the 2019 3rd International Conference on Information System and Data Mining},
pages = {129–132},
numpages = {4},
keywords = {Image classification, Machine learning, Fish identification},
location = {Houston, TX, USA},
series = {ICISDM 2019}
}

@inproceedings{10.1145/3055635.3056652,
author = {Kesvarakul, Ramil and Chianrabutra, Chamaporn and Chianrabutra, Srisit},
title = {Baby Shrimp Counting via Automated Image Processing},
year = {2017},
isbn = {9781450348171},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.sfu.ca/10.1145/3055635.3056652},
doi = {10.1145/3055635.3056652},
abstract = {The aim of this research is to investigate the method of detecting and counting baby shrimps by image processing technique. The experimental devices consist of a 1920x1080 pixels color image processing system and a light box. This light box is used as an indirect lighting source to avoid the bright spot from the target if the direct light technique is used. The shrimps are taken by a video camcorder, then the real time video is executed from the moving video to images and recorded them as the image files. The images are considered and converted to binary data types. Blob detection algorithm is used to detect the difference properties of color within the regions in the digital image. After that, the results from the image processing methodology are compared with the real value. It found that the shrimp quantity getting from the image processing technique is comparable and corresponding to the real shrimp quantity counting by manual with error is less than 7% of real quantity.},
booktitle = {Proceedings of the 9th International Conference on Machine Learning and Computing},
pages = {352–356},
numpages = {5},
keywords = {Image Processing, Counting, Baby Shrimp},
location = {Singapore, Singapore},
series = {ICMLC 2017}
}

@mastersthesis{dl-fish-rec,
    author = {Reithaug, Adrian},
    institution = {The University of Bergen},
    school = {The University of Bergen},
    title = {Employing Deep Learning for Fish Recognition},
    year = 2018
}

@mastersthesis{fish-det-sonar,
    author = {Ghobrial, Mina},
    institution = {University of Oulu},
    school = {University of Oulu},
    note = {\url{http://urn.fi/URN:NBN:fi:oulu-201906262667}},
    title = {Fish detection automation from ARIS and DIDSON SONAR data},
    year = 2019
}

@Article{Marini2018,
author={Marini, Simone
and Fanelli, Emanuela
and Sbragaglia, Valerio
and Azzurro, Ernesto
and Del Rio Fernandez, Joaquin
and Aguzzi, Jacopo},
title={Tracking Fish Abundance by Underwater Image Recognition},
journal={Scientific Reports},
year={2018},
month={Sep},
day={13},
volume={8},
number={1},
pages={13748},
abstract={Marine cabled video-observatories allow the non-destructive sampling of species at frequencies and durations that have never been attained before. Nevertheless, the lack of appropriate methods to automatically process video imagery limits this technology for the purposes of ecosystem monitoring. Automation is a prerequisite to deal with the huge quantities of video footage captured by cameras, which can then transform these devices into true autonomous sensors. In this study, we have developed a novel methodology that is based on genetic programming for content-based image analysis. Our aim was to capture the temporal dynamics of fish abundance. We processed more than 20,000 images that were acquired in a challenging real-world coastal scenario at the OBSEA-EMSO testing-site. The images were collected at 30-min. frequency, continuously for two years, over day and night. The highly variable environmental conditions allowed us to test the effectiveness of our approach under changing light radiation, water turbidity, background confusion, and bio-fouling growth on the camera housing. The automated recognition results were highly correlated with the manual counts and they were highly reliable when used to track fish variations at different hourly, daily, and monthly time scales. In addition, our methodology could be easily transferred to other cabled video-observatories.},
issn={2045-2322},
doi={10.1038/s41598-018-32089-8},
url={https://doi.org/10.1038/s41598-018-32089-8}
}

@article{DBLP:journals/corr/abs-1905-05241,
  author    = {Matias Valdenegro{-}Toro},
  title     = {Deep Neural Networks for Marine Debris Detection in Sonar Images},
  journal   = {CoRR},
  volume    = {abs/1905.05241},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.05241},
  archivePrefix = {arXiv},
  eprint    = {1905.05241},
  timestamp = {Tue, 28 May 2019 12:48:08 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1905-05241.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
